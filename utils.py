import numbers

import gym
import numpy as np

import matplotlib
matplotlib.use('TkAgg')
import matplotlib.pyplot as plt

import seaborn as sns
sns.set_style('white')

from scipy.signal import savgol_filter
from scipy.stats import norm, multivariate_normal

from tiles.tiles import tiles

def sample_gaussian(mu, sigma, x=None):
    if x is None:
        # return a sample from the normal distribution
        if isinstance(mu, numbers.Number):
            return np.random.normal(loc=mu, scale=sigma)[0]
        else:
            return np.random.multivariate_normal(mean=mu, cov=np.diag(sigma))
    else:
        # return p(x) under normal distribution specified by mu, sigma
        if isinstance(mu, numbers.Number):
            return norm.pdf(x, loc=mu, scale=sigma)
        else:
            return multivariate_normal.pdf(x, mean=mu, cov=np.diag(sigma))



def plot_rewards(reward_history, save_path, env_name, smooth=True):
    fig, ax = plt.subplots()
    if smooth:
        window = len(reward_history) / 100.
        # window must be odd
        window = window if window % 2 == 0 else window + 1
        reward_history = savgol_filter(reward_history, 501, 2)

    ax = sns.tsplot(reward_history, ax=ax)
    ax.set_xlabel('Episode')
    ax.set_ylabel('Total Reward')
    ax.set_title(env_name)
    sns.despine()

    plt.show()
    plt.savefig(save_path)
    plt.close()


def tile_state_space(env, n_tilings, grid_size=(4, 4)):
    """
    Return a function to encode the continous observations generated by `env`
    in terms of a collection of `n_tilings` overlapping tilings (each with
    dimension `grid_size`) of the state space.

    Arguments
    ---------
    env : gym.wrappers.time_limit.TimeLimit
        An openAI environment
    n_tilings : int
        The number of overlapping tilings to use. Should be a power of 2. This
        determines the dimension of the discretized tile-encoded state vector
    grid_size : list of length 2
        A list of ints representing the coarseness of the tilings. E.g., a
        `grid_size` of [4, 4] would mean each tiling consisted of a 4x4 tile
        grid

    Returns
    -------
    encode_obs_as_tile : function
        A function which takes as input continous observation vector and
        returns a set of the indices of the active tiles in the tile coded
        observation space
    n_states : int
        An integer reflecting the total number of unique states possible under
        this tile coding regimen
    """
    _, _, _, _ = check_continuous(env, 'Tile Coding', action=False, obs=True)
    obs_max = np.nan_to_num(env.observation_space.high)
    obs_min = np.nan_to_num(env.observation_space.low)
    obs_range = obs_max - obs_min

    scale = 1.0 / obs_range
    offset = 1.0 - (scale * obs_max)

    # scale observation vector to a point in the unit hypercube
    scale_obs = lambda obs: (obs * scale) + offset

    n_tiles = (np.prod(grid_size) * n_tilings)
    n_states = np.prod([n_tiles - i for i in range(n_tilings)])
    mem_size = np.min([n_tiles, 16384])

    def encode_obs_as_tile(obs):
        obs = scale_obs(obs)
        return tuple(sorted(tiles(n_tilings, mem_size, obs)))

    return encode_obs_as_tile, n_states


def softmax(obs, W, b):
    out = obs.dot(W) + b
    probs = np.exp(out) / np.sum(np.exp(out))
    return probs


def check_tuple(env):
    tuple_space = gym.spaces.tuple_space.Tuple

    is_tuple_action = isinstance(env.action_space, tuple_space)
    is_tuple_obs = isinstance(env.observation_space, tuple_space)
    return is_tuple_action, is_tuple_obs


def check_continuous(env, name='', action=True, obs=True):
    continuous = gym.spaces.box.Box
    is_tuple_action, is_tuple_obs = check_tuple(env)

    # action and observation spaces must by continuous
    if is_tuple_obs:
        is_continuous_obs = \
            all([isinstance(i, continuous)
                 for i in env.observation_space.spaces])

        if obs and not is_continuous_obs:
            raise TypeError('{} only works with continous '
                            'observation spaces'.format(name))

    else:
        is_continuous_obs = isinstance(env.observation_space, continuous)

        if obs and not is_continuous_obs:
            raise TypeError('{} only works with continous'
                            'observation spaces'.format(name))

    if is_tuple_action:
        is_continuous_action = \
            all([isinstance(i, continuous) for i in env.action_space.spaces])

        if action and not is_continuous_action:
            raise TypeError('{} only works with continuous '
                            'action spaces'.format(name))

    else:
        is_continuous_action = isinstance(env.action_space, continuous)
        if action and not is_continuous_action:
            raise TypeError('{} only works with continuous '
                            'action spaces'.format(name))

    return is_tuple_obs, is_tuple_action, is_continuous_obs, is_continuous_action


def check_discrete(env, name, action=True, obs=True):
    discrete = gym.spaces.discrete.Discrete
    is_tuple_action, is_tuple_obs = check_tuple(env)

    # action and observation spaces must by discrete for tabular learning
    if is_tuple_obs:
        is_disc_obs = all([isinstance(i, discrete)
                           for i in env.observation_space.spaces])
        if obs and not is_disc_obs:
            raise TypeError('{} Learner only works with discrete '
                            'observation spaces'.format(name))
    # action and observation spaces must by discrete for tabular learning
    else:
        is_disc_obs = isinstance(env.observation_space, discrete)
        if obs and not is_disc_obs:
            raise TypeError('{} Learner only works with discrete '
                            'observation spaces'.format(name))

    if is_tuple_action:
        is_disc_act = \
            all([isinstance(i, discrete) for i in env.action_space.spaces])

        if action and not is_disc_act:
            raise TypeError('{} Learner only works with discrete '
                            'action spaces'.format(name))

    else:
        is_disc_act = isinstance(env.action_space, discrete)
        if action and not is_disc_act:
            raise TypeError('{} Learner only works with discrete '
                            'action spaces'.format(name))

    return is_tuple_obs, is_tuple_action, is_disc_obs, is_disc_act
